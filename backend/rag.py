import os
from dotenv import load_dotenv
from langchain_upstage import ChatUpstage, UpstageEmbeddings
from typing import List, Dict, Optional, Tuple
from langchain_chroma import Chroma
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser
from datetime import datetime
import ast

load_dotenv()


class RAGPipeline:
    def __init__(
        self, vector_db_path: str = "data/vector_store/ê²½ì˜ì •ë³´ì‹œìŠ¤í…œ5_chroma_db"
    ):
        self.api_key = os.getenv("UPSTAGE_API_KEY")
        if not self.api_key:
            raise ValueError("UPSTAGE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # LLM ë° ì„ë² ë”© ì´ˆê¸°í™”
        self.llm = ChatUpstage(
            api_key=self.api_key,  # type: ignore
            model="solar-pro2",
            temperature=0.1,
        )

        self.embeddings = UpstageEmbeddings(
            api_key=self.api_key,  # type: ignore
            model="embedding-query",
        )

        # ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
        self.vector_store = self._load_vector_store(vector_db_path)

        # RAG ì²´ì¸ êµ¬ì„±
        self.rag_chain = self._create_rag_chain()

        print(f"ë²¡í„° DB: {vector_db_path}")

    def _load_vector_store(self, vector_db_path: str) -> Chroma:
        """ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ"""
        if not os.path.exists(vector_db_path):
            raise FileNotFoundError(f"ë²¡í„° DBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {vector_db_path}")

        print(f" ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì¤‘: {vector_db_path}")

        vector_store = Chroma(
            persist_directory=vector_db_path,
            embedding_function=self.embeddings,
            collection_name="mis_textbook",
        )

        # ë²¡í„°ìŠ¤í† ì–´ ìƒíƒœ í™•ì¸
        collection = vector_store._collection
        count = collection.count()
        print(f" ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ: {count}ê°œ ë¬¸ì„œ")

        return vector_store

    def _create_rag_chain(self):
        """RAG ì²´ì¸ ìƒì„±"""

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ 
        template = """You are an {topic} specialist. Give me MOST RELATIVE, ACCURATE TOPIC WORD based on textbook content provided.

**GUIDELINES:**
1. êµì¬ ë‚´ìš©ì— ê¸°ë°˜í•˜ì—¬ ì •í™•í•œ ëŒ€ì£¼ì œì–´ë¥¼ ì œê³µí•˜ì„¸ìš”.
2. ëŒ€ì£¼ì œì–´ê°€ ì—¬ëŸ¬ ê°œì´ë©´ ëª¨ë‘ ì ì–´ì£¼ì„¸ìš”(ìµœëŒ€ 3ê°œ).
3. ê° ì£¼ì œì–´ì—ëŠ” êµì¬ í˜ì´ì§€ ì •ë³´ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.
4. ì•„ë˜ ì¶œë ¥ í¬ë©§ì„ ê¼­ ì§€ì¼œì£¼ì„¸ìš”.
5. êµì¬ì— ì—†ëŠ” ë‚´ìš©ì´ë¼ë©´ ì¶”ì¸¡í•˜ì§€ ë§ê³  "[["",""]]"ë¥¼ ì¶œë ¥í•˜ì„¸ìš”

**OUTPUT FORMAT:**
"[['ì£¼ì œì–´', 'êµì¬ í˜ì´ì§€'], ['ì£¼ì œì–´2', 'êµì¬ í˜ì´ì§€2'], ...]"
- ì´ ì´ì™¸ì˜ ê·¼ê±° ê°™ì€ ë‹¤ë¥¸ ë‚´ìš©ì€ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ ê²ƒ

**TEXTBOOK CONTENT:**
{context}

**ì£¼ì œì–´:**"""

        prompt = ChatPromptTemplate.from_template(template)

        # RAG ì²´ì¸ êµ¬ì„± (ê°„ë‹¨í•˜ê²Œ ìˆ˜ì •)
        chain = prompt | self.llm | StrOutputParser()

        return chain

    def _format_docs(self, docs) -> str:
        """ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ì»¨í…ìŠ¤íŠ¸ í˜•íƒœë¡œ í¬ë§·íŒ…"""
        formatted_docs = []

        for i, doc in enumerate(docs, 1):
            metadata = doc.metadata
            content = doc.page_content

            # ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
            if len(content) > 500:
                content = content[:500] + "..."

            formatted_doc = f"""
[ë¬¸ì„œ {i}]
íŒŒì¼: {metadata.get("pdf_filename", "N/A")}
í˜ì´ì§€: {metadata.get("page_number", "N/A")}
ë‚´ìš©: {content}
"""
            formatted_docs.append(formatted_doc)

        return "\n".join(formatted_docs)

    def search_documents(
        self,
        query: str,
        k: int = 5,
        pdf_filter: Optional[str] = None,
        page_range: Optional[Tuple[int, int]] = None,
    ) -> List:
        """ê³ ê¸‰ ê²€ìƒ‰ ê¸°ëŠ¥"""

        # ê¸°ë³¸ ìœ ì‚¬ë„ ê²€ìƒ‰
        if pdf_filter or page_range:
            # ë©”íƒ€ë°ì´í„° í•„í„°ë§ì´ í•„ìš”í•œ ê²½ìš°
            all_docs = self.vector_store.similarity_search(
                query, k=k * 3
            )  # ë” ë§ì´ ê°€ì ¸ì™€ì„œ í•„í„°ë§

            filtered_docs = []
            for doc in all_docs:
                metadata = doc.metadata

                # PDF íŒŒì¼ í•„í„°
                if pdf_filter and pdf_filter not in metadata.get("pdf_filename", ""):
                    continue

                # í˜ì´ì§€ ë²”ìœ„ í•„í„°
                if page_range:
                    page_num = metadata.get("page_number", 0)
                    if not (page_range[0] <= page_num <= page_range[1]):
                        continue

                filtered_docs.append(doc)

                if len(filtered_docs) >= k:
                    break

            docs = filtered_docs
        else:
            docs = self.vector_store.similarity_search(query, k=k)
        return docs

    def ask_question(
        self,
        stt_input: str,
        topic: str,
        k: int = 5,
        pdf_filter: Optional[str] = None,
        page_range: Optional[Tuple[int, int]] = None,
        show_sources: bool = False,
    ) -> Dict:
        """ì§ˆë¬¸ ë‹µë³€ (ë©”ì¸ ê¸°ëŠ¥)"""

        # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        relevant_docs = self.search_documents(
            query=stt_input, k=k, pdf_filter=pdf_filter, page_range=page_range
        )

        if not relevant_docs:
            return {
                "query": stt_input,
                "relevant_docs": None,
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì„ êµì¬ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "sources": [],
                "timestamp": datetime.now().isoformat(),
            }

        # 2. LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±
        print("ğŸ¤– RAG LLM ë‹µë³€ ìƒì„± ì¤‘...")
        try:
            # ë¬¸ì„œë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…
            formatted_context = self._format_docs(relevant_docs)

            # RAG ì²´ì¸ ì‹¤í–‰
            answer = self.rag_chain.invoke(
                {
                    "topic": topic,
                    "context": formatted_context,
                }
            )
        except Exception as e:
            print(f" ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {
                "query": stt_input,
                "relevant_docs": relevant_docs,
                "answer": "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "sources": [],
                "timestamp": datetime.now().isoformat(),
            }

        # 3. ì†ŒìŠ¤ ì •ë³´ ìˆ˜ì§‘
        sources = []
        for doc in relevant_docs:
            metadata = doc.metadata
            sources.append(
                {
                    "file": metadata.get("pdf_filename", "N/A"),
                    "page": metadata.get("page_number", "N/A"),
                    "chunk_id": metadata.get("chunk_id", "N/A"),
                    "has_tables": metadata.get("has_tables", False),
                    "has_images": metadata.get("has_images", False),
                    "content_preview": doc.page_content[:200] + "..."
                    if len(doc.page_content) > 200
                    else doc.page_content,
                }
            )

        # 4. ê²°ê³¼ ì¶œë ¥
        answer = ast.literal_eval(answer)

        if show_sources:
            print("\nğŸ“š ì°¸ê³  ìë£Œ:")
            for i, source in enumerate(sources, 1):
                print(f"   [{i}] {source['file']} (p.{source['page']})")
                if source["has_tables"]:
                    print("       ğŸ“‹ í‘œ í¬í•¨")
                if source["has_images"]:
                    print("       ğŸ–¼ï¸ ì´ë¯¸ì§€ í¬í•¨")

        return {
            "query": stt_input,
            "relevant_docs": relevant_docs,
            "answer": answer,
            "sources": sources,
            "timestamp": datetime.now().isoformat(),
        }

    def interactive_chat(self):
        """ëŒ€í™”í˜• RAG ì‹œìŠ¤í…œ"""
        topic = str(input("ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”:"))

        conversation_history = []

        while True:
            try:
                user_input = input("\n ë‚´ìš©: ").strip()

                if user_input.lower() in ["quit", "exit", "ì¢…ë£Œ"]:
                    print("ğŸ‘‹ RAG ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break

                elif user_input == "/help":
                    self._show_help()
                    continue

                elif user_input.startswith("/"):
                    self._handle_command(user_input)
                    continue

                elif not user_input:
                    continue

                # ì§ˆë¬¸ ì²˜ë¦¬
                result = self.ask_question(user_input, topic)
                conversation_history.append(result)

            except KeyboardInterrupt:
                print("\nğŸ‘‹ RAG ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f" ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    def _show_help(self):
        """ë„ì›€ë§ í‘œì‹œ"""
        help_text = """
ğŸ”§ ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´:
   /search <ê²€ìƒ‰ì–´>     - ë‹¨ìˆœ ê²€ìƒ‰ (ë‹µë³€ ìƒì„± ì—†ì´ ë¬¸ì„œë§Œ ì°¾ê¸°)
   /stats              - ë²¡í„°ìŠ¤í† ì–´ í†µê³„ ì •ë³´
   /help               - ì´ ë„ì›€ë§
   quit/exit           - í”„ë¡œê·¸ë¨ ì¢…ë£Œ

ğŸ’¡ ì§ˆë¬¸ ì˜ˆì‹œ:
   "ê²½ì˜ì •ë³´ì‹œìŠ¤í…œì´ë€ ë¬´ì—‡ì¸ê°€ìš”?"
   "ì‹œìŠ¤í…œì˜ êµ¬ì„±ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
   "ì •ë³´ ì²˜ë¦¬ ì£¼ê¸°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”"
        """
        print(help_text)

    def _handle_command(self, command: str):
        """ëª…ë ¹ì–´ ì²˜ë¦¬"""
        if command.startswith("/search "):
            query = command[8:].strip()
            docs = self.search_documents(query)
            print(f"\nğŸ” '{query}' ê²€ìƒ‰ ê²°ê³¼:")
            for i, doc in enumerate(docs, 1):
                metadata = doc.metadata
                print(
                    f"   [{i}] {metadata.get('pdf_filename')} (p.{metadata.get('page_number')})"
                )

        elif command == "/stats":
            collection = self.vector_store._collection
            count = collection.count()
            print("\n ë²¡í„°ìŠ¤í† ì–´ í†µê³„:")
            print(f"    ì´ ë¬¸ì„œ ìˆ˜: {count}")
            print("    ì»¬ë ‰ì…˜ëª…: mis_textbook")

        else:
            print(" ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´ì…ë‹ˆë‹¤. '/help'ë¡œ ë„ì›€ë§ì„ í™•ì¸í•˜ì„¸ìš”.")


if __name__ == "__main__":
    topic = str(input("topic:"))
    stt_input = str(input("content:"))
    RAGPipeline().ask_question(stt_input, topic)
